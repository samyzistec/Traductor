{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer desde cero para Traducción Náhuatl (ncx) ↔ Español (es)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n## Documentación robusta — Transformer Nahuatl (ncx) ↔ Español (es)\n\n**Proyecto:** *articulo traduccion Nahualt-español*  \n**Implementación principal:** Transformer “from scratch” en PyTorch + baseline opcional **BERT2BERT (mBERT)**.  \n**Destino:** Notebook único: `Transformer_Nahuatl_Espanol_FromScratch.ipynb`\n\n### 1) Objetivo y alcance\nConstruir un sistema de traducción automática **bidireccional** `ncx ↔ es` con:\n\n- **Preprocesamiento específico:** segmentación por oraciones, normalización a minúsculas y preservación de **diacríticos, glotal, puntuación y números**.  \n- **Tokenización:** SentencePiece **Unigram** con **vocabulario compartido** (ncx+es) ≈ **10k**.  \n- **Modelo desde cero:** Transformer **Pre-Norm**, `d_model=512`, `n_heads=8`, `d_ff=2048`, `n_layers=6/6`, `dropout=0.1`.  \n- **Entrenamiento:** Adam + **Noam**, **label smoothing=0.1**, **bucketing** por longitud, **grad clip=1.0**.  \n- **Evaluación:** *sacreBLEU* y **chrF++**.  \n- **Inferencia:** *greedy* y **beam search** (beam configurable).  \n- **UI:** **Gradio** embebida en el notebook.  \n- **Baseline opcional:** **BERT2BERT (mBERT)** con HuggingFace para comparación.\n\n### 2) Requisitos\n**Software**\n- Python 3.9–3.11  \n- Paquetes mínimos: `sentencepiece`, `sacrebleu`, `gradio`, `tqdm`, `pyyaml`, `torch`  \n- Opcionales: `transformers`, `accelerate`, `datasets` (baseline), `torch-directml` (Windows/AMD), `spacy` + `es_core_news_sm`\n\n**Instalación (celda 0)**\n```bash\n%pip install sentencepiece sacrebleu gradio tqdm pyyaml pandas\n%pip install transformers accelerate datasets  # baseline opcional\n%pip install torch-directml                    # opcional AMD/DirectML\n# %pip install spacy && python -m spacy download es_core_news_sm  # opcional\n```\n\n**Hardware**\n- Funciona en **CPU**. Si tienes **GPU AMD** en Windows, prueba **DirectML** (`torch-directml`). El notebook lo detecta automáticamente.\n\n### 3) Datos\n**Carpeta base:** `C:\\\\Users\\\\Samuel Perez\\\\Desktop\\\\articulo`\n\nEstructura esperada:\n```\narticulo/\n├─ salida/\n│  └─ parallel_ncx_es.jsonl       # corpus paralelo (requerido)\n├─ spm/                           # modelos SentencePiece\n├─ checkpoints/                   # pesos del modelo\n└─ logs/\n```\n\n**Formato del corpus (`parallel_ncx_es.jsonl`)**\nCada línea es un JSON como:\n```json\n{\"src\": \"<texto nahuatl>\", \"tgt\": \"<texto español>\", \"libro\":\"Génesis\", \"capitulo\":1, \"versiculo\":\"1\"}\n```\nCampos `libro`, `capitulo`, `versiculo` opcionales (trazabilidad).\n\nSi necesitas **CSV→JSONL**:\n```python\nimport csv, json, pathlib\ncsv_path = pathlib.Path(r\"C:\\Users\\Samuel Perez\\Desktop\\articulo\\corpus_ncx_es.csv\")\njsonl_path = pathlib.Path(r\"C:\\Users\\Samuel Perez\\Desktop\\articulo\\salida\\parallel_ncx_es.jsonl\")\nwith open(csv_path, newline='', encoding='utf-8') as f, open(jsonl_path, 'w', encoding='utf-8') as w:\n    for row in csv.DictReader(f):\n        obj = {\"src\": row[\"ncx\"].strip(), \"tgt\": row[\"es\"].strip()}\n        w.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n```\n\n### 4) Tokenización — SentencePiece (Unigram, vocab compartido)\n- `VOCAB_SIZE = 10000` (rango 8k–12k).  \n- Símbolos especiales: `<pad>`, `<bos>`, `<eos>`, `<lang_ncx>`, `<lang_es>`.  \n- `character_coverage = 1.0` para preservar diacríticos.  \n- Salida: `spm/ncx_es_unigram.model`, `spm/ncx_es_unigram.vocab`.\n\n### 5) Modelo “from scratch” (PyTorch)\n**Small (por defecto):** `d_model=512, n_heads=8, d_ff=2048, n_layers=6/6, dropout=0.1`  \n**Light (memoria baja):** `d_model=256, n_heads=4, d_ff=1024, n_layers=4/4`  \n- Pre‑Norm, positional encoding seno/coseno, **padding mask** y **causal mask** en decoder.\n\n### 6) Entrenamiento\n- `MAX_LEN=128`, **bucketing** por longitud.  \n- Adam(β1=0.9, β2=0.98, eps=1e-9) + **Noam** (`warmup=4000`).  \n- Regularización: **label smoothing=0.1**, **dropout=0.1**, **grad_clip=1.0**.  \n- **Grad Accum**: 1 (sube a 2–4 si reduces batch).  \n- Recomendación (**salida recomendada**): `CFG_SMALL`, `EPOCHS=2`, `BATCH=32`, `WARMUP=4000`, `BEAM=5`, `length_penalty=0.7`.\n\n### 7) Evaluación\n- **sacreBLEU** y **chrF++** por dirección (`ncx→es` y `es→ncx`).  \n- En bajo‑recursos, **chrF++** suele ser más sensible.\n\n### 8) Inferencia y UI\n- *Greedy* y **beam search**.  \n- **Gradio** con selector de dirección y slider de beam (`demo.launch()`).\n\n### 9) Baseline — BERT2BERT (mBERT)\n- `EncoderDecoderModel` con `bert-base-multilingual-cased` (freezing parcial).\n\n### 10) Flujo de trabajo rápido\n1. Revisa `parallel_ncx_es.jsonl`.  \n2. Ejecuta celdas 0–7 (deps, rutas, datos, splits, SentencePiece).  \n3. Entrena celdas 11 (ambas direcciones).  \n4. Evalúa (celda 12).  \n5. UI (celda 13).  \n6. Baseline 14.x (opcional).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Dependencias (ejecuta si hace falta)\n```bash\n%pip install sentencepiece sacrebleu gradio tqdm pyyaml pandas\n# Opcional:\n%pip install transformers accelerate datasets\n%pip install torch-directml\n# %pip install spacy && python -m spacy download es_core_news_sm\n```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 1) Rutas, semillas y splits\nfrom pathlib import Path\nimport os, random, numpy as np, torch\n\nBASE_DIR = Path(r\"C:\\Users\\Samuel Perez\\Desktop\\articulo\")\nfor p in [BASE_DIR, BASE_DIR/\"salida\", BASE_DIR/\"checkpoints\", BASE_DIR/\"spm\", BASE_DIR/\"logs\"]:\n    p.mkdir(parents=True, exist_ok=True)\n\nDATA_DIR = BASE_DIR / \"salida\"\nCHECK_DIR = BASE_DIR / \"checkpoints\"\nTOK_DIR = BASE_DIR / \"spm\"\nLOG_DIR = BASE_DIR / \"logs\"\n\nPARALLEL_JSONL = DATA_DIR / \"parallel_ncx_es.jsonl\"\nassert PARALLEL_JSONL.exists(), f\"No se encontró {PARALLEL_JSONL}. Coloca el corpus en esa ruta.\"\n\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n\nSPLIT_TRAIN = 0.8\nSPLIT_DEV   = 0.1\nMAX_SAMPLES = 0\nMAX_LEN     = 128\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 2) Dispositivo\nimport torch\nDEVICE = torch.device(\"cpu\")\ntry:\n    import torch_directml\n    DEVICE = torch_directml.device()\n    print(\"Usando DirectML (GPU AMD) si está disponible.\")\nexcept Exception as e:\n    print(\"DirectML no disponible; usando CPU.\\n\", str(e))\nprint(\"DEVICE =\", DEVICE)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 3) Carga de datos + segmentación\nimport json, re\nfrom typing import List\n\ndef sent_split_es(text: str) -> List[str]:\n    try:\n        import spacy\n        try: nlp = spacy.load(\"es_core_news_sm\")\n        except Exception:\n            nlp = spacy.blank(\"es\"); nlp.add_pipe(\"sentencizer\")\n        return [s.text.strip() for s in nlp(text).sents if s.text.strip()]\n    except Exception:\n        parts = re.split(r\"(?<=[\\.\\?\\!¡¿])\\s+\", text.strip())\n        return [p.strip() for p in parts if p.strip()]\n\ndef sent_split_ncx(text: str) -> List[str]:\n    parts = re.split(r\"(?<=[\\.\\?\\!])\\s+\", text.strip())\n    return [p.strip() for p in parts if p.strip()]\n\npairs = []\nwith open(PARALLEL_JSONL, \"r\", encoding=\"utf-8\") as f:\n    for line in f:\n        obj = json.loads(line)\n        s = obj[\"src\"].strip(); t = obj[\"tgt\"].strip()\n        if s and t: pairs.append((s, t, obj.get(\"libro\",\"\"), obj.get(\"capitulo\",0), obj.get(\"versiculo\",0)))\nprint(f\"Pares cargados (verso): {len(pairs):,}\")\n\nexpanded = []\nfor s, t, libro, cap, ver in pairs:\n    ss = sent_split_ncx(s.lower()); tt = sent_split_es(t.lower())\n    if 1 < len(ss) == len(tt) < 10:\n        for i in range(len(ss)):\n            expanded.append((ss[i], tt[i], libro, cap, f\"{ver}.{i+1}\"))\n    else:\n        expanded.append((s.lower(), t.lower(), libro, cap, ver))\n\nif MAX_SAMPLES and MAX_SAMPLES>0:\n    expanded = expanded[:MAX_SAMPLES]\nprint(f\"Pares tras segmentación: {len(expanded):,}\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 4) Splits\nfrom math import floor\nidx = list(range(len(expanded))); random.shuffle(idx)\nn_tr = floor(len(idx)*SPLIT_TRAIN); n_de = floor(len(idx)*SPLIT_DEV)\ndef take(idxs): return [expanded[i] for i in idxs]\ntrain_pairs = take(idx[:n_tr])\ndev_pairs   = take(idx[n_tr:n_tr+n_de])\ntest_pairs  = take(idx[n_tr+n_de:])\nprint(f\"Train={len(train_pairs):,} | Dev={len(dev_pairs):,} | Test={len(test_pairs):,}\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 5) SentencePiece (Unigram, vocab compartido)\nimport sentencepiece as spm\n\nVOCAB_SIZE = 10000\nraw_corpus = (TOK_DIR / \"spm_raw.txt\")\nwith open(raw_corpus, \"w\", encoding=\"utf-8\") as w:\n    for s, t, *_ in train_pairs + dev_pairs:\n        w.write(s + \"\\n\"); w.write(t + \"\\n\")\n\nSPM_MODEL_PREFIX = str((TOK_DIR / \"ncx_es_unigram\").as_posix())\nspm.SentencePieceTrainer.Train(\n    input=str(raw_corpus),\n    model_prefix=SPM_MODEL_PREFIX,\n    vocab_size=VOCAB_SIZE,\n    model_type=\"unigram\",\n    user_defined_symbols=[\"<pad>\",\"<bos>\",\"<eos>\",\"<lang_ncx>\",\"<lang_es>\"],\n    character_coverage=1.0,\n    input_sentence_size=1000000,\n    shuffle_input_sentence=True,\n)\n\nSPM_MODEL = TOK_DIR / \"ncx_es_unigram.model\"\nSPM_VOCAB = TOK_DIR / \"ncx_es_unigram.vocab\"\nassert SPM_MODEL.exists(), \"No se generó el modelo SentencePiece.\"\nprint(\"Tokenizador entrenado →\", SPM_MODEL)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 6) Tokenización helpers\nsp = spm.SentencePieceProcessor(model_file=str(SPM_MODEL))\n\nPAD_ID  = sp.piece_to_id(\"<pad>\")\nBOS_ID  = sp.piece_to_id(\"<bos>\")\nEOS_ID  = sp.piece_to_id(\"<eos>\")\nLNCX_ID = sp.piece_to_id(\"<lang_ncx>\")\nLES_ID  = sp.piece_to_id(\"<lang_es>\")\nVOCAB   = sp.get_piece_size()\n\ndef encode_with_lang(text, lang_tok_id):\n    ids = sp.encode(text, out_type=int)\n    return [BOS_ID, lang_tok_id] + ids + [EOS_ID]\n\ndef collate_batch(batch, pad_id=PAD_ID):\n    src_lens = [len(b[0]) for b in batch]\n    tgt_lens = [len(b[1]) for b in batch]\n    max_src = min(max(src_lens), MAX_LEN)\n    max_tgt = min(max(tgt_lens), MAX_LEN)\n    def pad_seq(seq, L):\n        seq = seq[:L]; return seq + [pad_id]*(L - len(seq))\n    import torch\n    src = torch.tensor([pad_seq(b[0], max_src) for b in batch], dtype=torch.long)\n    tgt = torch.tensor([pad_seq(b[1], max_tgt) for b in batch], dtype=torch.long)\n    return src, tgt\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 7) Dataset + bucketing\nfrom torch.utils.data import Dataset, DataLoader\nimport random\n\nclass ParallelDataset(Dataset):\n    def __init__(self, pairs, direction=\"ncx2es\"):\n        self.items = []\n        for s, t, *_ in pairs:\n            if direction==\"ncx2es\":\n                self.items.append((encode_with_lang(s, LNCX_ID), encode_with_lang(t, LES_ID)))\n            else:\n                self.items.append((encode_with_lang(t, LES_ID), encode_with_lang(s, LNCX_ID)))\n    def __len__(self): return len(self.items)\n    def __getitem__(self, i): return self.items[i]\n\ndef make_loader(pairs, direction, batch_size=32, shuffle=True):\n    ds = ParallelDataset(pairs, direction=direction)\n    order = sorted(range(len(ds)), key=lambda i: len(ds.items[i][0]))\n    if shuffle:\n        B=50; buckets=[order[i::B] for i in range(B)]\n        order=[i for b in buckets for i in random.sample(b, len(b))]\n    class _Proxy(Dataset):\n        def __len__(self): return len(order)\n        def __getitem__(self, j): return ds.items[order[j]]\n    return DataLoader(_Proxy(), batch_size=batch_size, collate_fn=collate_batch)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 8) Transformer (Pre‑Norm) desde cero\nimport math\nimport torch, torch.nn as nn\n\nDROPOUT = 0.1\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=2048):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n        pe[:,0::2] = torch.sin(position*div_term)\n        pe[:,1::2] = torch.cos(position*div_term)\n        self.register_buffer('pe', pe.unsqueeze(0))\n    def forward(self, x): return x + self.pe[:, :x.size(1)]\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, n_heads, dropout=0.1):\n        super().__init__()\n        assert d_model % n_heads == 0\n        self.d_k = d_model // n_heads; self.n = n_heads\n        self.q = nn.Linear(d_model, d_model); self.k = nn.Linear(d_model, d_model)\n        self.v = nn.Linear(d_model, d_model); self.o = nn.Linear(d_model, d_model)\n        self.dropout = nn.Dropout(dropout)\n    def forward(self, q, k, v, attn_mask=None, key_padding_mask=None):\n        B,Lq,D = q.shape; B,Lk,_ = k.shape\n        q = self.q(q).view(B,Lq,self.n,self.d_k).transpose(1,2)\n        k = self.k(k).view(B,Lk,self.n,self.d_k).transpose(1,2)\n        v = self.v(v).view(B,Lk,self.n,self.d_k).transpose(1,2)\n        scores = torch.matmul(q, k.transpose(-2,-1))/math.sqrt(self.d_k)\n        if attn_mask is not None:\n            if attn_mask.dim()==2: scores = scores + attn_mask.unsqueeze(0).unsqueeze(0)\n            elif attn_mask.dim()==4: scores = scores + attn_mask\n        if key_padding_mask is not None:\n            mask = key_padding_mask.unsqueeze(1).unsqueeze(2)\n            scores = scores.masked_fill(mask, float('-inf'))\n        attn = torch.softmax(scores, dim=-1)\n        attn = self.dropout(attn)\n        out  = torch.matmul(attn, v).transpose(1,2).contiguous().view(B, Lq, D)\n        return self.o(out)\n\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(d_model, d_ff), nn.ReLU(), nn.Dropout(dropout), nn.Linear(d_ff, d_model))\n    def forward(self, x): return self.net(x)\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(d_model); self.attn = MultiHeadAttention(d_model, n_heads, dropout); self.drop1 = nn.Dropout(dropout)\n        self.norm2 = nn.LayerNorm(d_model); self.ff   = FeedForward(d_model, d_ff, dropout);    self.drop2 = nn.Dropout(dropout)\n    def forward(self, x, src_pad_mask):\n        y = self.attn(self.norm1(x), self.norm1(x), self.norm1(x), key_padding_mask=src_pad_mask); x = x + self.drop1(y)\n        y = self.ff(self.norm2(x)); x = x + self.drop2(y); return x\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(d_model); self.self_attn = MultiHeadAttention(d_model, n_heads, dropout); self.drop1 = nn.Dropout(dropout)\n        self.norm2 = nn.LayerNorm(d_model); self.cross_attn = MultiHeadAttention(d_model, n_heads, dropout); self.drop2 = nn.Dropout(dropout)\n        self.norm3 = nn.LayerNorm(d_model); self.ff = FeedForward(d_model, d_ff, dropout); self.drop3 = nn.Dropout(dropout)\n    def forward(self, x, mem, tgt_pad_mask, tgt_causal_mask, mem_pad_mask):\n        y = self.self_attn(self.norm1(x), self.norm1(x), self.norm1(x), attn_mask=tgt_causal_mask, key_padding_mask=tgt_pad_mask); x = x + self.drop1(y)\n        y = self.cross_attn(self.norm2(x), mem, mem, key_padding_mask=mem_pad_mask); x = x + self.drop2(y)\n        y = self.ff(self.norm3(x)); x = x + self.drop3(y); return x\n\nclass TransformerModel(nn.Module):\n    def __init__(self, vocab_size, d_model, n_heads, d_ff, n_enc, n_dec, dropout=0.1, pad_id=0):\n        super().__init__()\n        self.pad_id = pad_id\n        self.emb = nn.Embedding(vocab_size, d_model, padding_idx=pad_id)\n        self.pos = PositionalEncoding(d_model)\n        self.encoder = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_enc)])\n        self.decoder = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_dec)])\n        self.proj = nn.Linear(d_model, vocab_size)\n    def make_pad_mask(self, seq): return seq.eq(self.pad_id)\n    def make_causal_mask(self, L):\n        mask = torch.triu(torch.ones(L, L, device=self.emb.weight.device), diagonal=1)\n        return mask.masked_fill(mask==1, float('-inf'))\n    def encode(self, src):\n        src_pad = self.make_pad_mask(src); x = self.pos(self.emb(src))\n        for layer in self.encoder: x = layer(x, src_pad)\n        return x, src_pad\n    def decode(self, tgt, mem, mem_pad):\n        tgt_pad = self.make_pad_mask(tgt); x = self.pos(self.emb(tgt))\n        causal = self.make_causal_mask(tgt.size(1)).unsqueeze(0).unsqueeze(0)\n        for layer in self.decoder: x = layer(x, mem, tgt_pad, causal, mem_pad)\n        return self.proj(x)\n    def forward(self, src, tgt_in):\n        mem, src_pad = self.encode(src); return self.decode(tgt_in, mem, src_pad)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 9) Loss (Label Smoothing), Noam y métricas\nimport torch.nn as nn, torch\nclass LabelSmoothingLoss(nn.Module):\n    def __init__(self, classes, smoothing=0.1, ignore_index=0):\n        super().__init__(); self.ignore_index=ignore_index; self.confidence=1.0-smoothing; self.smoothing=smoothing; self.cls=classes\n    def forward(self, pred, target):\n        pred = pred.view(-1, pred.size(-1)); target = target.reshape(-1)\n        log_probs = torch.log_softmax(pred, dim=-1)\n        nll = -log_probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1)\n        smooth = -log_probs.mean(dim=-1)\n        pad_mask = target.eq(self.ignore_index)\n        loss = self.confidence*nll + self.smoothing*smooth\n        return (loss.masked_fill(pad_mask,0).sum() / torch.clamp((~pad_mask).sum(), min=1))\n\nclass NoamWrapper:\n    def __init__(self, optimizer, d_model, warmup=4000):\n        self.opt=optimizer; self.d_model=d_model; self.warm=warmup; self.step_num=0\n    def step(self):\n        self.step_num += 1\n        lr = (self.d_model ** -0.5) * min(self.step_num ** -0.5, self.step_num * (self.warm ** -1.5))\n        for pg in self.opt.param_groups: pg['lr']=lr\n        self.opt.step()\n    def zero_grad(self): self.opt.zero_grad()\n    @property\n    def lr(self): return self.opt.param_groups[0]['lr']\n\ntry:\n    from sacrebleu.metrics import BLEU, CHRF\n    bleu = BLEU(force=True); chrf = CHRF(word_order=2)\nexcept Exception as e:\n    print(\"sacrebleu no disponible:\", e); bleu=chrf=None\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 10) Eval/greedy + CFGs\nimport torch\ndef batch_to_device(b, device): return b[0].to(device), b[1].to(device)\n\ndef evaluate(model, loader, device):\n    model.eval(); total=0.0; n=0\n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = batch_to_device((src,tgt), device)\n            logits = model(src, tgt[:, :-1])\n            crit = LabelSmoothingLoss(VOCAB, 0.1, PAD_ID)\n            loss = crit(logits, tgt[:,1:]); total += loss.item(); n += 1\n    return total / max(n,1)\n\ndef ids_to_text(ids):\n    ids = [i for i in ids if i not in (PAD_ID, BOS_ID)]\n    if ids and ids[-1] == EOS_ID: ids = ids[:-1]\n    return sp.decode(ids)\n\ndef translate_greedy(model, src_ids, max_len=MAX_LEN, tgt_lang_id=LES_ID):\n    model.eval()\n    src = torch.tensor([src_ids], dtype=torch.long, device=model.emb.weight.device)\n    mem, src_pad = model.encode(src)\n    ys = torch.tensor([[BOS_ID, tgt_lang_id]], dtype=torch.long, device=src.device)\n    for _ in range(max_len):\n        logits = model.decode(ys, mem, src_pad)\n        nxt = logits[:,-1,:].argmax(dim=-1, keepdim=True)\n        ys = torch.cat([ys, nxt], dim=1)\n        if nxt.item() == EOS_ID: break\n    return ys[0].tolist()\n\nCFG_SMALL = dict(d_model=512, n_heads=8, d_ff=2048, n_enc=6, n_dec=6)\nCFG_LIGHT = dict(d_model=256, n_heads=4, d_ff=1024, n_enc=4, n_dec=4)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 10b) Logging CSV + Early Stopping + Resume\nimport csv, pathlib\nfrom datetime import datetime\n\ndef ensure_logfile(direction):\n    LOG_DIR.mkdir(parents=True, exist_ok=True)\n    path = LOG_DIR / f\"train_log_{direction}.csv\"\n    if not path.exists():\n        with open(path, \"w\", encoding=\"utf-8\", newline=\"\") as w:\n            csv.writer(w).writerow([\"timestamp\",\"direction\",\"epoch\",\"steps\",\"lr\",\"train_loss\",\"dev_loss\",\"dev_bleu\",\"dev_chrf\",\"best_so_far\"])\n    return path\n\ndef translate_greedy_dir(model, src_ids, direction=\"ncx2es\", max_len=MAX_LEN):\n    tgt_lang = LES_ID if direction==\"ncx2es\" else LNCX_ID\n    return translate_greedy(model, src_ids, max_len=max_len, tgt_lang_id=tgt_lang)\n\ndef compute_dev_metrics(model, direction=\"ncx2es\", max_samples=200):\n    ds = ParallelDataset(dev_pairs, direction=direction)\n    if len(ds) == 0: return (0.0, 0.0)\n    up = min(len(ds), max_samples)\n    refs, hyps = [], []\n    for i in range(up):\n        src_ids, tgt_ids = ds[i]\n        out_ids = translate_greedy_dir(model, src_ids, direction=direction, max_len=MAX_LEN)\n        refs.append([ids_to_text(tgt_ids)]); hyps.append(ids_to_text(out_ids))\n    try:\n        from sacrebleu.metrics import BLEU, CHRF\n        bleu_val = BLEU(force=True).corpus_score(hyps, list(zip(*refs))).score\n        chrf_val = CHRF(word_order=2).corpus_score(hyps, list(zip(*refs))).score\n        return (bleu_val, chrf_val)\n    except Exception:\n        return (0.0, 0.0)\n\ndef save_checkpoint(model, save_prefix, d_model, n_heads, d_ff, n_enc, n_dec, pad_id, vocab, direction, epoch, noam_step=0):\n    CHECK_DIR.mkdir(parents=True, exist_ok=True)\n    path = (CHECK_DIR / f\"{save_prefix}_best.pt\").as_posix()\n    torch.save({\"model\":model.state_dict(),\n                \"cfg\":{\"d_model\":d_model,\"n_heads\":n_heads,\"d_ff\":d_ff,\"n_enc\":n_enc,\"n_dec\":n_dec,\"pad_id\":pad_id,\"vocab\":vocab},\n                \"meta\":{\"direction\":direction,\"epoch\":epoch,\"noam_step\":noam_step,\"spm_model\":str(SPM_MODEL)}},\n               path)\n    return path\n\ndef train_direction(direction=\"ncx2es\",\n                    epochs=2, batch_size=32, grad_accum=1,\n                    d_model=512, n_heads=8, d_ff=2048, n_enc=6, n_dec=6,\n                    warmup=4000, save_prefix=\"scratch_ncx2es\",\n                    patience=3, dev_metric_samples=200, init_model=None, start_epoch=1):\n    print(f\"\\n=== Entrenando dirección: {direction} ===\")\n    train_loader = make_loader(train_pairs, direction, batch_size=batch_size, shuffle=True)\n    dev_loader   = make_loader(dev_pairs,   direction, batch_size=batch_size, shuffle=False)\n\n    model = TransformerModel(VOCAB, d_model, n_heads, d_ff, n_enc, n_dec, DROPOUT, PAD_ID) if init_model is None else init_model\n    model.to(DEVICE)\n\n    opt = torch.optim.Adam(model.parameters(), betas=(0.9,0.98), eps=1e-9)\n    noam = NoamWrapper(opt, d_model, warmup=warmup)\n    crit = LabelSmoothingLoss(VOCAB, 0.1, PAD_ID)\n\n    log_path = ensure_logfile(direction)\n    best_dev_chrf = -1e9; epochs_no_improve = 0; best_path = None; global_step = 0\n\n    for ep in range(start_epoch, start_epoch + epochs):\n        model.train(); total=0.0; n=0; opt.zero_grad()\n        for i, (src, tgt) in enumerate(train_loader, 1):\n            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n            logits = model(src, tgt[:, :-1])\n            loss = crit(logits, tgt[:, 1:]) / grad_accum\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            if i % grad_accum == 0:\n                noam.step(); noam.zero_grad()\n            total += loss.item()*grad_accum; n += 1; global_step += 1\n            if i % 100 == 0:\n                print(f\"ep{ep} step{i} lr={noam.lr:.6f} loss={total/max(n,1):.4f}\")\n\n        dev_loss = evaluate(model, dev_loader, DEVICE)\n        dev_bleu, dev_chrf = compute_dev_metrics(model, direction=direction, max_samples=dev_metric_samples)\n        print(f\"[Ep {ep}] dev_loss={dev_loss:.4f} | BLEU={dev_bleu:.2f} | chrF++={dev_chrf:.2f}\")\n\n        with open(log_path, \"a\", encoding=\"utf-8\", newline=\"\") as w:\n            csv.writer(w).writerow([datetime.utcnow().isoformat(), direction, ep, global_step,\n                                    f\"{noam.lr:.8f}\", f\"{total/max(n,1):.6f}\", f\"{dev_loss:.6f}\",\n                                    f\"{dev_bleu:.4f}\", f\"{dev_chrf:.4f}\", \"yes\" if dev_chrf>best_dev_chrf else \"no\"])\n\n        if dev_chrf > best_dev_chrf:\n            best_dev_chrf = dev_chrf\n            best_path = save_checkpoint(model, save_prefix, d_model, n_heads, d_ff, n_enc, n_dec, PAD_ID, VOCAB, direction, ep, noam.step_num)\n            print(\"Mejora en chrF++; guardado mejor modelo en\", best_path)\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            print(f\"Sin mejora de chrF++ por {epochs_no_improve}/{patience} épocas\")\n            if epochs_no_improve >= patience:\n                print(\"Early stopping activado.\"); break\n\n    return best_path, best_dev_chrf\n\ndef load_for_resume(ckpt_path):\n    data = torch.load(ckpt_path, map_location=\"cpu\")\n    cfg = data[\"cfg\"]; meta = data.get(\"meta\", {})\n    model = TransformerModel(cfg[\"vocab\"], cfg[\"d_model\"], cfg[\"n_heads\"], cfg[\"d_ff\"], cfg[\"n_enc\"], cfg[\"n_dec\"], pad_id=cfg[\"pad_id\"])\n    model.load_state_dict(data[\"model\"]); model.to(DEVICE)\n    return model, cfg, meta\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 11) Entrenamiento (ambas direcciones)\nEPOCHS = 2; BATCH = 32; ACCUM = 1; WARMUP = 4000\nbest_ncx2es, _ = train_direction(\"ncx2es\", epochs=EPOCHS, batch_size=BATCH, grad_accum=ACCUM, warmup=WARMUP, save_prefix=\"scratch_ncx2es\", **CFG_SMALL)\nbest_es2ncx, _ = train_direction(\"es2ncx\", epochs=EPOCHS, batch_size=BATCH, grad_accum=ACCUM, warmup=WARMUP, save_prefix=\"scratch_es2ncx\", **CFG_SMALL)\nprint(\"Mejores checkpoints:\", best_ncx2es, best_es2ncx)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 12) Evaluación\nfrom pathlib import Path\ndef load_model(path):\n    data = torch.load(path, map_location=\"cpu\")\n    cfg = data[\"cfg\"]\n    model = TransformerModel(cfg[\"vocab\"], cfg[\"d_model\"], cfg[\"n_heads\"], cfg[\"d_ff\"], cfg[\"n_enc\"], cfg[\"n_dec\"], pad_id=cfg[\"pad_id\"])\n    model.load_state_dict(data[\"model\"]); model.to(DEVICE); model.eval()\n    return model\n\ndef eval_direction(best_path, direction=\"ncx2es\", max_samples=200):\n    if best_path is None or not Path(best_path).exists():\n        print(\"Checkpoint no encontrado:\", best_path); return\n    model = load_model(best_path)\n    ds = ParallelDataset(test_pairs, direction=direction)\n    refs, hyps = [], []\n    for i in range(min(len(ds), max_samples)):\n        src_ids, tgt_ids = ds[i]\n        out_ids = translate_greedy(model, src_ids, max_len=MAX_LEN, tgt_lang_id=(LES_ID if direction=='ncx2es' else LNCX_ID))\n        refs.append([ids_to_text(tgt_ids)]); hyps.append(ids_to_text(out_ids))\n    try:\n        from sacrebleu.metrics import BLEU, CHRF\n        print(direction, \"BLEU:\", BLEU(force=True).corpus_score(hyps, list(zip(*refs))))\n        print(direction, \"chrF++:\", CHRF(word_order=2).corpus_score(hyps, list(zip(*refs))))\n    except Exception as e:\n        print(\"sacrebleu no disponible:\", e)\n\neval_direction(best_ncx2es, \"ncx2es\")\neval_direction(best_es2ncx, \"es2ncx\")\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 13) UI Gradio\nimport gradio as gr, torch\ndef translate_beam(model, src_ids, beam=5, lp=0.7, max_len=MAX_LEN, tgt_lang_id=LES_ID):\n    model.eval()\n    device = model.emb.weight.device\n    src = torch.tensor([src_ids], dtype=torch.long, device=device)\n    mem, src_pad = model.encode(src)\n    beams = [([BOS_ID, tgt_lang_id], 0.0)]; finished = []\n    for _ in range(max_len):\n        new_beams = []\n        for seq, score in beams:\n            if seq[-1] == EOS_ID:\n                finished.append((seq, score)); continue\n            ys = torch.tensor([seq], dtype=torch.long, device=device)\n            logits = model.decode(ys, mem, src_pad)[:,-1,:].squeeze(0)\n            logp = torch.log_softmax(logits, dim=-1).detach().cpu()\n            topk = torch.topk(logp, beam).indices.tolist()\n            for tok in topk:\n                new_beams.append((seq+[tok], score+logp[tok].item()))\n        beams = sorted(new_beams, key=lambda x: x[1]/((len(x[0])**lp)), reverse=True)[:beam]\n        if not beams: break\n    if not finished: finished = beams\n    best = max(finished, key=lambda x: x[1]/((len(x[0])**lp)))\n    return best[0]\n\nBEST_NCX2ES = best_ncx2es if 'best_ncx2es' in globals() else None\nBEST_ES2NCX = best_es2ncx if 'best_es2ncx' in globals() else None\n\ndef _load_model_(path):\n    data = torch.load(path, map_location=\"cpu\")\n    cfg = data[\"cfg\"]; m = TransformerModel(cfg[\"vocab\"], cfg[\"d_model\"], cfg[\"n_heads\"], cfg[\"d_ff\"], cfg[\"n_enc\"], cfg[\"n_dec\"], pad_id=cfg[\"pad_id\"])\n    m.load_state_dict(data[\"model\"]); m.eval(); return m\n\ndef load_scratch(direction):\n    from pathlib import Path\n    path = BEST_NCX2ES if direction==\"ncx2es\" else BEST_ES2NCX\n    if path is None or not Path(path).exists(): return None, f\"Checkpoint no encontrado: {path}\"\n    return _load_model_(path), f\"Cargado: {path}\"\n\ndef infer_scratch(text, direction=\"ncx2es\", beam=5):\n    if not text.strip(): return \"\"\n    model, msg = load_scratch(direction)\n    lang_id = LES_ID if direction==\"ncx2es\" else LNCX_ID\n    src_lang = LNCX_ID if direction==\"ncx2es\" else LES_ID\n    src_ids = encode_with_lang(text.lower(), src_lang)\n    out_ids = translate_beam(model, src_ids, beam=beam, tgt_lang_id=lang_id)\n    return ids_to_text(out_ids)\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## Traductor (Transformer desde cero)\")\n    direction = gr.Radio(choices=[\"ncx2es\",\"es2ncx\"], value=\"ncx2es\", label=\"Dirección\")\n    beam = gr.Slider(1, 10, step=1, value=5, label=\"Beam size\")\n    inp = gr.Textbox(lines=3, label=\"Texto de entrada\")\n    out = gr.Textbox(lines=3, label=\"Traducción\")\n    btn = gr.Button(\"Traducir\")\n    btn.click(fn=infer_scratch, inputs=[inp, direction, beam], outputs=[out])\nprint(\"Para lanzar la UI: demo.launch()\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14) Baseline opcional — BERT2BERT (mBERT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "from datasets import Dataset as HFDataset\nfrom transformers import BertTokenizerFast, EncoderDecoderModel, TrainingArguments, Trainer, DataCollatorForSeq2Seq\nHF_DIR = BASE_DIR / \"hf_bert2bert\"; HF_DIR.mkdir(parents=True, exist_ok=True)\ntok_hf = BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")\ndef build_hf_split(pairs, direction=\"ncx2es\"):\n    srcs, tgts = [], []\n    for s, t, *_ in pairs:\n        if direction==\"ncx2es\": srcs.append(s); tgts.append(t)\n        else: srcs.append(t); tgts.append(s)\n    return HFDataset.from_dict({\"src\":srcs, \"tgt\":tgts})\nhf_train = build_hf_split(train_pairs, \"ncx2es\")\nhf_dev   = build_hf_split(dev_pairs,   \"ncx2es\")\ndef tok_map(batch):\n    model_inputs = tok_hf(batch[\"src\"], truncation=True, max_length=MAX_LEN)\n    with tok_hf.as_target_tokenizer():\n        labels = tok_hf(batch[\"tgt\"], truncation=True, max_length=MAX_LEN)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\nhf_train_tok = hf_train.map(tok_map, batched=True, remove_columns=[\"src\",\"tgt\"])\nhf_dev_tok   = hf_dev.map(tok_map,   batched=True, remove_columns=[\"src\",\"tgt\"])\nenc_dec = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-multilingual-cased\", \"bert-base-multilingual-cased\")\nfor name, param in enc_dec.named_parameters():\n    if \"encoder.embeddings\" in name or \"encoder.encoder.layer.0\" in name or \"decoder.embeddings\" in name:\n        param.requires_grad = False\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tok_hf, model=enc_dec)\nargs = TrainingArguments(output_dir=str(HF_DIR), per_device_train_batch_size=4, per_device_eval_batch_size=4,\n                         evaluation_strategy=\"epoch\", learning_rate=5e-5, num_train_epochs=1,\n                         save_total_limit=1, logging_steps=50, report_to=\"none\")\ntrainer = Trainer(model=enc_dec, args=args, data_collator=data_collator, tokenizer=tok_hf,\n                  train_dataset=hf_train_tok, eval_dataset=hf_dev_tok)\n# trainer.train()\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 16) Matrices de confusión — utilidades (SPM y carácter)\nimport numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom collections import Counter\n\ndef _align_levenshtein(ref, hyp):\n    m, n = len(ref), len(hyp)\n    dp = [[0]*(n+1) for _ in range(m+1)]\n    back = [[None]*(n+1) for _ in range(m+1)]\n    for i in range(1, m+1):\n        dp[i][0] = i; back[i][0] = 'D'\n    for j in range(1, n+1):\n        dp[0][j] = j; back[0][j] = 'I'\n    for i in range(1, m+1):\n        for j in range(1, n+1):\n            cost = 0 if ref[i-1] == hyp[j-1] else 1\n            opts = [\n                (dp[i-1][j] + 1, 'D'),\n                (dp[i][j-1] + 1, 'I'),\n                (dp[i-1][j-1] + cost, 'M' if cost==0 else 'S')\n            ]\n            dp[i][j], back[i][j] = min(opts, key=lambda x: x[0])\n    i, j = m, n\n    a_ref, a_hyp = [], []\n    while i>0 or j>0:\n        op = back[i][j]\n        if op == 'M' or op == 'S':\n            a_ref.append(ref[i-1]); a_hyp.append(hyp[j-1]); i-=1; j-=1\n        elif op == 'D':\n            a_ref.append(ref[i-1]); a_hyp.append('<eps>'); i-=1\n        elif op == 'I':\n            a_ref.append('<eps>'); a_hyp.append(hyp[j-1]); j-=1\n        else:\n            break\n    a_ref.reverse(); a_hyp.reverse()\n    return a_ref, a_hyp\n\ndef _pieces_from_ids(ids):\n    specials = {PAD_ID, BOS_ID, EOS_ID, LNCX_ID, LES_ID}\n    return [sp.id_to_piece(i) for i in ids if i not in specials]\n\ndef _char_list(text):\n    return [c for c in text.replace(\" \", \"\")]\n\ndef _count_confusions(aligned_ref, aligned_hyp):\n    cnt = Counter()\n    for r, h in zip(aligned_ref, aligned_hyp):\n        cnt[(r, h)] += 1\n    return cnt\n\ndef _top_labels(counter, top_n=200, include_eps=True):\n    from collections import Counter as C\n    freq_ref = C()\n    for (r, h), c in counter.items():\n        freq_ref[r] += c\n    labels = [tok for tok, _ in freq_ref.most_common(top_n)]\n    other = \"<other>\"\n    if \"<eps>\" in labels: labels.remove(\"<eps>\")\n    if include_eps and \"<eps>\" not in labels:\n        labels = labels + [\"<eps>\"]\n    if other not in labels:\n        labels = labels + [other]\n\n    freq_hyp = C()\n    for (r, h), c in counter.items():\n        freq_hyp[h] += c\n    cols = [tok for tok, _ in freq_hyp.most_common(top_n)]\n    if include_eps and \"<eps>\" not in cols:\n        cols = cols + [\"<eps>\"]\n    if other not in cols:\n        cols = cols + [other]\n    return labels, cols\n\ndef _matrix_from_counter(counter, rows, cols):\n    idx = {t:i for i,t in enumerate(rows)}\n    jdx = {t:j for j,t in enumerate(cols)}\n    import numpy as np\n    mat = np.zeros((len(rows), len(cols)), dtype=int)\n    for (r,h), c in counter.items():\n        rkey = r if r in idx else \"<other>\"\n        hkey = h if h in jdx else \"<other>\"\n        ri = idx.get(rkey, idx[\"<other>\"])\n        hj = jdx.get(hkey, jdx[\"<other>\"])\n        mat[ri, hj] += c\n    return mat\n\ndef _save_confusion_outputs(mat, rows, cols, out_prefix):\n    import pandas as pd, matplotlib.pyplot as plt, numpy as np, os\n    os.makedirs(os.path.dirname(out_prefix), exist_ok=True)\n    df = pd.DataFrame(mat, index=rows, columns=cols)\n    df.to_csv(out_prefix + \".csv\", encoding=\"utf-8\")\n    plt.figure(figsize=(10, 7))\n    plt.imshow(mat, aspect=\"auto\")\n    plt.colorbar()\n    plt.xticks(ticks=np.arange(len(cols)), labels=cols, rotation=90, fontsize=7)\n    plt.yticks(ticks=np.arange(len(rows)), labels=rows, fontsize=7)\n    plt.title(\"Confusion Matrix\")\n    plt.tight_layout()\n    plt.savefig(out_prefix + \".png\", dpi=150)\n    plt.close()\n\ndef _save_top_pairs(counter, out_csv, k=50):\n    import pandas as pd, os\n    os.makedirs(os.path.dirname(out_csv), exist_ok=True)\n    data = sorted([(*k_, v) for k_, v in counter.items() if k_[0] != k_[1]], key=lambda x: x[2], reverse=True)[:k]\n    df = pd.DataFrame(data, columns=[\"ref\", \"hyp\", \"count\"])\n    df.to_csv(out_csv, index=False, encoding=\"utf-8\")\n\ndef _build_sequences(level, ref_text, hyp_text, ref_ids=None, hyp_ids=None):\n    if level == \"spm\":\n        rseq = _pieces_from_ids(ref_ids) if ref_ids is not None else sp.encode(ref_text, out_type=str)\n        hseq = _pieces_from_ids(hyp_ids) if hyp_ids is not None else sp.encode(hyp_text, out_type=str)\n    elif level == \"char\":\n        rseq = _char_list(ref_text); hseq = _char_list(hyp_text)\n    else:\n        raise ValueError(\"level debe ser 'spm' o 'char'\")\n    return rseq, hseq\n\ndef confusion_for_dataset(model, dataset, direction=\"ncx2es\", level=\"spm\", top_n=200, beam=5, max_samples=500, out_dir=None, tag=\"dev\"):\n    from tqdm import tqdm, trange\n    cnt = Counter()\n    N = min(len(dataset), max_samples)\n    tgt_lang_id = LES_ID if direction == \"ncx2es\" else LNCX_ID\n    for i in tqdm(range(N), desc=f\"Confusion {tag} {direction} {level}\"):\n        src_ids, tgt_ids = dataset[i]\n        out_ids = translate_beam(model, src_ids, beam=beam, tgt_lang_id=tgt_lang_id)\n        ref_text = ids_to_text(tgt_ids); hyp_text = ids_to_text(out_ids)\n        rseq, hseq = _build_sequences(level, ref_text, hyp_text, ref_ids=tgt_ids, hyp_ids=out_ids if level==\"spm\" else None)\n        a_r, a_h = _align_levenshtein(rseq, hseq)\n        cnt += _count_confusions(a_r, a_h)\n    rows, cols = _top_labels(cnt, top_n=top_n, include_eps=True)\n    mat = _matrix_from_counter(cnt, rows, cols)\n    import os\n    os.makedirs(out_dir, exist_ok=True)\n    prefix = os.path.join(out_dir, f\"confusion_{tag}_{direction}_{level}\")\n    _save_confusion_outputs(mat, rows, cols, prefix)\n    _save_top_pairs(cnt, os.path.join(out_dir, f\"top_pairs_{tag}_{direction}_{level}.csv\"), k=50)\n    return prefix\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 17) Ejecutar matrices de confusión (ambas direcciones, dev/test, SPM+char)\nTOP_N = 200; BEAM = 5; MAX_SAMPLES = 500\nOUT_DIR = (LOG_DIR / \"analytics\").as_posix()\n\nfrom pathlib import Path\n\ndef load_model(path):\n    data = torch.load(path, map_location=\"cpu\")\n    cfg = data[\"cfg\"]\n    model = TransformerModel(cfg[\"vocab\"], cfg[\"d_model\"], cfg[\"n_heads\"], cfg[\"d_ff\"], cfg[\"n_enc\"], cfg[\"n_dec\"], pad_id=cfg[\"pad_id\"])\n    model.load_state_dict(data[\"model\"]); model.to(DEVICE); model.eval()\n    return model\n\ndef _get_model_for(direction):\n    try:\n        if direction == \"ncx2es\" and 'best_ncx2es' in globals() and best_ncx2es:\n            path = best_ncx2es\n        elif direction == \"es2ncx\" and 'best_es2ncx' in globals() and best_es2ncx:\n            path = best_es2ncx\n        else:\n            fname = \"scratch_ncx2es_best.pt\" if direction==\"ncx2es\" else \"scratch_es2ncx_best.pt\"\n            path = (CHECK_DIR / fname).as_posix()\n        print(\"Cargando\", path)\n        model = load_model(path)\n        return model\n    except Exception as e:\n        print(\"No fue posible cargar el modelo:\", e)\n        return None\n\ndef run_confusions():\n    sets = [(\"dev\", dev_pairs), (\"test\", test_pairs)]\n    dirs = [\"ncx2es\", \"es2ncx\"]\n    levels = [\"spm\", \"char\"]\n    for direction in dirs:\n        model = _get_model_for(direction)\n        if model is None: \n            print(\"Omitiendo\", direction, \"por falta de modelo.\"); \n            continue\n        for tag, pairs_set in sets:\n            ds = ParallelDataset(pairs_set, direction=direction)\n            for level in levels:\n                prefix = confusion_for_dataset(model, ds, direction=direction, level=level,\n                                               top_n=TOP_N, beam=BEAM, max_samples=MAX_SAMPLES,\n                                               out_dir=OUT_DIR, tag=tag)\n                print(\"Guardado:\", prefix + \".csv/png\")\n\n# Para ejecutar cuando tengas entrenados los modelos:\n# run_confusions()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 18) Visualización de confusiones (Top‑20)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# 18) Visualización de confusiones (Top-20)\nimport os, glob\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nANALYTICS_DIR = (LOG_DIR / \"analytics\").as_posix()\nPLOT_DIR = (LOG_DIR / \"analytics\" / \"plots\").as_posix()\nPath(PLOT_DIR).mkdir(parents=True, exist_ok=True)\n\ndef list_top_pair_csvs():\n    pattern = os.path.join(ANALYTICS_DIR, \"top_pairs_*.csv\")\n    files = sorted(glob.glob(pattern))\n    print(f\"Encontrados {len(files)} archivos top_pairs_*.csv\")\n    return files\n\ndef plot_top20(csv_path, top_k=20):\n    df = pd.read_csv(csv_path)\n    if \"count\" not in df.columns:\n        print(\"CSV sin columna 'count':\", csv_path); return None\n    df2 = df.sort_values(\"count\", ascending=False).head(top_k)\n    labels = [f\"{r}→{h}\" for r, h in zip(df2[\"ref\"], df2[\"hyp\"])]\n    plt.figure(figsize=(10, 6))\n    plt.barh(range(len(df2)), df2[\"count\"].values)\n    plt.yticks(range(len(df2)), labels)\n    plt.gca().invert_yaxis()\n    plt.xlabel(\"Frecuencia\")\n    plt.title(os.path.basename(csv_path).replace(\"top_pairs_\", \"\").replace(\".csv\",\"\"))\n    plt.tight_layout()\n    out_png = os.path.join(PLOT_DIR, \"confusion_plot_\" + os.path.basename(csv_path).replace(\"top_pairs_\", \"\").replace(\".csv\",\".png\"))\n    plt.savefig(out_png, dpi=150)\n    plt.show()\n    print(\"Guardado:\", out_png)\n    return out_png\n\ndef generate_all_top20_plots():\n    outs = []\n    for f in list_top_pair_csvs():\n        out = plot_top20(f, top_k=20)\n        if out: outs.append(out)\n    return outs\n\n# Descomenta para generar las gráficas una vez tengas CSVs:\n# generate_all_top20_plots()\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}